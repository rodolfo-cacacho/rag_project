{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Table Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and basic functions Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API KEY ChatGPT: sk-proj-FrNMaLZT7tgBftIDPuBOT3BlbkFJFND9eOXtUMeCyWxplFlV\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from database_manager import MySQLDB\n",
    "from pydantic import BaseModel\n",
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY_CGPT = os.getenv('API_KEY_CGPT')\n",
    "print(f'Loaded API KEY ChatGPT: {API_KEY_CGPT}')\n",
    "openai.api_key = API_KEY_CGPT\n",
    "MODEL=\"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt_api_with_single_prompt(instructions, prompt, model=\"gpt-4o-2024-08-06\", max_tokens=2500, response_format=None, img_path=None,detail='high'):\n",
    "    \"\"\"\n",
    "    Sends a single message to GPT API with optional image input and retrieves the response.\n",
    "    \n",
    "    Parameters:\n",
    "    - instructions: System instructions to set the context (e.g., \"You are an AI assistant that analyzes tables\").\n",
    "    - prompt: User's message or query (e.g., \"Please analyze the table in the image and provide a summary\").\n",
    "    - model: The GPT model to be used (default is \"gpt-4o-2024-08-06\").\n",
    "    - max_tokens: Maximum number of tokens for the response (default is 2500).\n",
    "    - response_format: Format of the response (e.g., \"Rag_reponse\"). Defaults to standard completion if not provided.\n",
    "    - img_path: Optional path to an image file. If provided, the image will be included in the request.\n",
    "    \n",
    "    Returns:\n",
    "    - The GPT answer object.\n",
    "    \"\"\"\n",
    "\n",
    "    content = []\n",
    "    dict_images = []\n",
    "    # Create the messages list to send to GPT\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions}\n",
    "    ]\n",
    "\n",
    "    # If an image path is provided, encode and append it as a separate message\n",
    "    if img_path:\n",
    "        base64_image = encode_image(img_path)\n",
    "        prompt_text = {'type':'text','text':dedent(prompt)}\n",
    "        dic_images = {'type':'image_url','image_url':{'url': f\"data:image/png;base64,{base64_image}\",'detail':detail}}\n",
    "        dict_images.append(dic_images)\n",
    "        content.append(prompt_text)\n",
    "        content.extend(dict_images)\n",
    "        chat = {\"role\": \"user\", \"content\":content}\n",
    "\n",
    "    else:\n",
    "        print(\"a\")\n",
    "        # Append the image message to the conversation\n",
    "        chat = {\"role\": \"user\", \"content\":dedent(prompt)}\n",
    "    \n",
    "    messages.append(chat)\n",
    "    \n",
    "    try:\n",
    "        if response_format == None:\n",
    "            # Call GPT API using OpenAI's beta chat completions with parse\n",
    "            response = openai.beta.chat.completions.parse(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens)\n",
    "        else:\n",
    "            # Call GPT API using OpenAI's beta chat completions with parse\n",
    "            response = openai.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            response_format=response_format)\n",
    "\n",
    "        # Extract and return the response content\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during GPT API call: {e}\")\n",
    "        return None\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"\n",
    "    Encodes an image to base64 for transmission.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: The path to the image to encode.\n",
    "    \n",
    "    Returns:\n",
    "    - Base64 encoded image as a string.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Meta-Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_idea - Die Tabelle listet förderfähige Heizkesselmodelle des Herstellers Hargassner auf. Sie beschreibt die Nennwärmeleistung, den Kesselwirkungsgrad, CO-Emissionen, Staubemissionen und CO-Meßteil bei verschiedenen Anlagentypen. Diese Informationen sind entscheidend für die Förderung nach BAFA-Richtlinien.\n",
      "instruction_set - Analysiere Tabellen aus regulatorischen Dokumenten und extrahiere detaillierte, zeilenbezogene Informationen. Achte auf wichtige Werte wie Prozentsätze, Einheiten und besondere Hinweise. Strukturiere die Daten für spätere Verwendung und Abrufbarkeit.\n",
      "generated_prompt - Extrahiere die folgenden Informationen zu jedem Anlagentyp aus der Tabelle: Hersteller, Anlagentyp, Nennwärmeleistung (kW), Kesselwirkungsgrad (%), CO bei Nennlast (mg/m³), Staub bei Nennlast (mg/m³), CO-Meßteil (mg/m³). Achte darauf, alle Einheiten und wichtigen Hinweise zu berücksichtigen.\n"
     ]
    }
   ],
   "source": [
    "class meta_prompt_reponse(BaseModel):\n",
    "    main_idea: str\n",
    "    instruction_set: str\n",
    "    generated_prompt: str\n",
    "\n",
    "instruction_set = \"\"\"You are an AI assistant specialized in analyzing tables from regulatory documents. Your task is to:\n",
    "1. Analyze the provided table and summarize its main idea or purpose concisely in German.\n",
    "2. Generate a new tailored prompt that can be used to extract detailed row-level data from the table in a structured way for retrieval purposes.\n",
    "\n",
    "The new prompt should guide the system to extract each row's data, ensuring important values like percentages, units, and any special notes are included.\n",
    "\"\"\"\n",
    "prompt = \"\"\"Please analyze the following table and complete the following three tasks:\n",
    "\n",
    "1. Summarize the main idea of the table in **German**, focusing on key points such as the regulations, data categories, or the overall content it covers.\n",
    "\n",
    "2. Generate a **new set of system instructions** to pair up with the generated prompt. It should give clear instructions to the system, specifying their role and expertise. Set the behaviour to pair up with the generated prompt. The descriptions have to be in **german**.\n",
    "   \n",
    "3. Generate a **new prompt** that can be used to extract a detailed **row-level description** from the table. This new prompt should be optimized for retrieving important values like **percentages, units, and special notes**. Ensure that the description is suitable for embedding and later retrieval.\n",
    "\n",
    "The goal is to make the row extraction as efficient and informative as possible. \n",
    "\"\"\"\n",
    "# img_path = '/Users/rodolfocacacho/Documents/Documents/MAI/Master Thesis/Code/rag_clean_v2/data/documents/output/Richtlinie BEG EM/Richtlinie BEG EM (2023-12-21)/tables/fileoutpart4.png'\n",
    "img_path = '/Users/rodolfocacacho/Documents/Documents/MAI/Master Thesis/Code/rag_clean_v2/data/documents/output/Liste förderfähigen Anlagen - Biomasse/BEG EM Liste förderfähigen Biomasse (2021-02-17)/part0/tables/fileoutpart24.png'\n",
    "\n",
    "response = call_gpt_api_with_single_prompt(instructions=instruction_set,\n",
    "                                prompt=prompt,\n",
    "                                img_path=img_path,\n",
    "                                response_format=meta_prompt_reponse)\n",
    "\n",
    "response_l = json.loads(response)\n",
    "for i in response_l:\n",
    "    print(f'{i} - {response_l[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_description = response_l['main_idea']\n",
    "prompt_ext_table = response_l['generated_prompt']\n",
    "system_ext_instructions = response_l['instruction_set']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Meta-Prompt and Table Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class row_description(BaseModel):\n",
    "    row_description: str\n",
    "\n",
    "class table_description(BaseModel):\n",
    "    rows: list[row_description]\n",
    "\n",
    "response_rows = call_gpt_api_with_single_prompt(img_path=img_path,\n",
    "                                                response_format=table_description,\n",
    "                                                prompt=prompt_ext_table,\n",
    "                                                instructions=system_ext_instructions)\n",
    "\n",
    "response_rows_l = json.loads(response_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECO-HK 170 mit eCleaner (Pellets), Nennwärmeleistung: 166.0 kW, Kesselwirkungsgrad: 93.4%, CO bei Nennlast: 12.0 mg/m³, Staub bei Nennlast: 13.0 mg/m³, CO-Meßteil: 51.0 mg/m³.\n",
      "ECO-HK 170 (PK), Nennwärmeleistung: 170.0 kW, Kesselwirkungsgrad: 94.3%, CO bei Nennlast: 15.0 mg/m³, Staub bei Nennlast: 10.0 mg/m³, CO-Meßteil: 61.0 mg/m³.\n",
      "ECO-HK 199, Nennwärmeleistung: 199.0 kW, Kesselwirkungsgrad: 94.5%, CO bei Nennlast: 12.0 mg/m³, Staub bei Nennlast: 11.0 mg/m³, CO-Meßteil: 73.0 mg/m³.\n",
      "ECO-HK 200, Nennwärmeleistung: 200.0 kW, Kesselwirkungsgrad: 94.8%, CO bei Nennlast: 13.0 mg/m³, Staub bei Nennlast: 11.0 mg/m³, CO-Meßteil: 70.0 mg/m³.\n",
      "ECO-HK 220, Nennwärmeleistung: 216.0 kW, Kesselwirkungsgrad: 95.5%, CO bei Nennlast: 13.0 mg/m³, Staub bei Nennlast: 9.0 mg/m³, CO-Meßteil: 43.0 mg/m³.\n"
     ]
    }
   ],
   "source": [
    "for i in response_rows_l:\n",
    "    rows = response_rows_l[i]\n",
    "    for j in rows:\n",
    "        print(j['row_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_table(elements,db_connector,pdf_file_name,pdf_file_type,db_table_name,directory):\n",
    "\n",
    "    new_elements = []\n",
    "\n",
    "    for i,element in enumerate(elements):\n",
    "        type_element = element['type']\n",
    "        if type_element == 'Table':\n",
    "            table_path = element['filePaths']\n",
    "            if i<len(elements)-1:\n",
    "                next_type = elements[i+1]['type']\n",
    "                if next_type == 'Footnote':\n",
    "                    content_ft = elements[i+1]['content']\n",
    "                else:\n",
    "                    content_ft = ''\n",
    "            else:\n",
    "                content_ft = ''\n",
    "            \n",
    "            table_sum_dict = {'pdf_type': pdf_file_type,\n",
    "                              'pdf_name': pdf_file_name,\n",
    "                              'table_path': table_path}\n",
    "            # print(f'table Path: {table_path}\\n{table_sum_dict}')\n",
    "            ids = db_connector.find_record_id(db_table_name,table_sum_dict)\n",
    "\n",
    "            if ids == None:\n",
    "                table_path_comp = os.path.join(directory,table_path)\n",
    "                summary = gpt_call_table_description(table_path_comp,content_ft)\n",
    "                # summary = ''\n",
    "                table_sum_dict['description'] = summary\n",
    "                table_sum_dict['footnote'] = content_ft\n",
    "                db_connector.insert_record(db_table_name,table_sum_dict)\n",
    "            \n",
    "            else:\n",
    "                #LOAD ID\n",
    "                record = db_connector.get_record_by_id(db_table_name,ids)\n",
    "                summary = record[4]\n",
    "\n",
    "            # save_table_description()\n",
    "            element['content'] = summary\n",
    "            new_elements.append(element)\n",
    "        elif type_element == 'Footnote':\n",
    "            continue\n",
    "        else:\n",
    "            new_elements.append(element)\n",
    "            \n",
    "    return elements\n",
    "\n",
    "\n",
    "def gpt_call_table_description(file_path,footnote):\n",
    "\n",
    "    question = \"\"\"Please analyze the provided image of a table and create a concise description in German that includes the following details:\n",
    "\n",
    "\t1.\tOverview: Mention the primary manufacturers and the types of models listed in the table.\n",
    "\t2.\tModel Variations: Identify any significant variations in the models, such as different series or types, and use the first letters or key differentiators to clarify distinctions.\n",
    "\t3.\tManufacturer Diversity: List the different manufacturers included in the table.\n",
    "\t4.\tValue Ranges: Provide the range of key technical values (e.g., heating output, efficiency) that apply to the models listed.\n",
    "\t5.\tCertification and Unique Attributes: Mention any certifications (e.g., BAFA) or unique attributes that apply to all or most of the models.\n",
    "\n",
    "Ensure the description is concise, clear, and in German, reflecting the language of the table data.\"\"\"\n",
    "\n",
    "    if footnote != '':\n",
    "        ft_note = f'Use the following footnote to interpret the image: {footnote}'\n",
    "    else:\n",
    "        ft_note = ''\n",
    "\n",
    "    description = chat_gpt_api_call_image(img_path= file_path,question= question,footnote=ft_note)\n",
    "\n",
    "    return description\n",
    "\n",
    "\n",
    "def chat_gpt_api_call_image(img_path,question = 'Describe the following image',footnote=''):\n",
    "\n",
    "    base64_image = encode_image(img_path)\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": question},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"Summarize the following image.\\n{footnote}\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{base64_image}\"}\n",
    "                }\n",
    "            ]}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    summary = response\n",
    "    summary = summary.choices[0].message.content\n",
    "\n",
    "    return summary\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Rows with Table Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bundesbaubot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
